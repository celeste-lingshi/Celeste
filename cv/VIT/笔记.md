

**Transfomer的内容可以看 Attention is All you need 这篇**

![](./img/ViT%E6%A8%A1%E5%9E%8B.png)

ViT模型是应用于图像分类领域。因此，其模型结构相较于传统的Transformer有以下几个特点：

1. 数据集的原图像被划分为多个patch后，将二维patch（不考虑channel）转换为一维向量，再加上类别向量与位置向量作为模型输入。
2. 模型主体的Block基于Transformer的Encoder部分，但是调整了normaliztion的位置，其中，最主要的结构依然是Multi-head Attention结构。
3. 模型在Blocks堆叠后接全连接层接受类别向量输出用于分类。通常情况下，我们将最后的全连接层称为Head，Transformer Encoder部分为backbone。



将TransformerEncoder结构和一个多层感知器（MLP）结合，就构成了ViT模型的backbone部分。

