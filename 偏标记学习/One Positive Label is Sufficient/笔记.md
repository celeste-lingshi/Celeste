# One Positive Label is Sufficient: Single-Positive Multi-Label Learning with Label Enhancement

本文提出了一种新的SPMLL方法SILE，即带标签增强的单正多标签学习方法。具体地说，给出了一个无偏风险估计器，它可以保证在全监督学习中近似收敛到最优风险最小化器，并表明每个实例的一个正标签足以训练一个模型。然后，通过恢复潜在软标签作为标签增强过程，建立相应的经验风险估计器，其中潜在软标签的后验密度近似于由推理模型参数化的变分Beta密度。


* 多类分类（Multiclass Classification）
一个样本属于且只属于多个类中的一个，一个样本只能属于一个类，不同类之间是互斥的。
典型方法：
  * One-vs-All or One-vs.-rest：
将多类问题分成N个二类分类问题，训练N个二类分类器，对第i个类来说，所有属于第i个类的样本为正（positive）样本，其他样本为负（negative）样本，每个二类分类器将属于i类的样本从其他类中分离出来。

  * One-vs-One or All-vs-All：
训练出N(N-1)个二类分类器，每个分类器区分一对类 $(i,j)$ 。

* 多标签分类(multilabel classification)
又称，多标签学习、多标记学习，不同于多类分类，一个样本可以属于多个类别（或标签），不同类之间是有关联的。

***

在本文中，我们提出了一种理论上有保证的方法，称为 SMILE，即带有标签增强的单正多标签学习。具体来说，首先推导出一个无偏风险估计器，这表明每个实例的一个正标签足以训练多标签学习的预测模型。此外，推导了估计误差界限，保证了所提出方法的风险一致性。然后，我们可以通过在标签增强过程中恢复与每个示例对应的软标签来设计基准解决方案 ，其中潜在软标签的后验密度是通过利用近似的 Beta 密度来推断的。贡献总结如下：

1. 从理论上，我们首次推导出了SPMLL的无偏风险估计。在此基础上，建立了保证风险一致性的估计误差界，并证明了在全监督MLL中得到的风险最小值将近似收敛于最优风险最小值。
2. 在实践中，我们提出了利用标签增强恢复潜在软标签的SMILE方法。利用近似贝塔密度推导出潜在软标签的后验密度，并推导出优化的证据下限(ELBO)。


# 相关工作

在多标签学习中，每个示例同时与多个类标签相关联。由于 MLL 中的输出空间与类标签的数量呈指数关系，因此提出了许多方法来利用标签相关性来促进学习过程。一阶方法将 MLL 问题分解为许多二元分类问题。二阶方法考虑标签对之间的标签相关性。高阶方法进一步关注标签集之间的标签相关性。另一项研究侧重于通过将特定于标签的特征形式化到每个类标签，从而操纵特征空间。

此外，一些工作侧重于通过深度模型处理MLL。通过使用GCN在所有标签节点之间传播信息。还有使用Transformer通过引入三进制编码方案来表示标签的状态，用于探索标签依赖性


# 问题设置

## 多标记学习
在MLL中，每个示例都与多个标签相关联，旨在构建一个预测模型，该模型可以为不可见的实例分配一组相关标签。设 $\mathcal X = \mathbb R^q$ 是q维实例空间，$\mathcal Y= \{ 1，2，\cdots，c \}$ 是带有 $c$ 类标签的标签空间。给定MLL训练集 $\mathcal D = \{(x_i,Y_i)| 1 \leq i \leq n\}$ 其中 $x_i∈ \mathcal X$ 表示 $q$ 维实例， $Y_i \in \mathcal C$ 是与 $x_i$ 相关的一组相关标签，其中 $\mathcal C=2^{\mathcal Y}$ 。多标签学习的任务是诱导一个多标签分类器 $f:\mathcal X \to 2^{\mathcal Y}$ ，将以下分类风险降至最低：
$$R(f) = \mathbb E_{p(x,Y)} [\mathcal L(f(x),Y)]$$

其中 $\mathcal L : \mathbb R^q \times 2^{\mathcal Y} \to \mathbb R_+$

## 单正多标记学习

SPMLL训练集 $\tilde {\mathcal D} = \{(x_i,\gamma_i) | 1 \leq i \leq n  \}$ 其中 $\gamma_i \in \mathcal Y$ 表示实例 $x_i$ 被观测到的单正标签。 $\gamma_i \in Y_i$ ，但相关标签集 $Y_i$ 并不可以直接被学习算法访问。

对于每个SPMLL训练示例 $(x_i， \gamma_i)$ ，我们使用观察到的单正向量 $l_i = [l^1_i, l^2_i,\cdots,l^c_i]^T \in \{ 0,1\}^c$ 来表示第 $j$ 个标记是否是观测到的正标记，即如果 $j = \gamma_i$ ，则 $l^j_i = 1$ ，否则 $l^j_i = 0$ 。多标签向量用 $y_i = [y^1_i, y^2_i ,\cdots ,y^c_i]^T \in \{0,1\}^c$ 表示。其中，如果第 $j$ 个标签与 $x_i$ 相关，则 $y^j_i = 1$ ，否则 $y^j_i = 0$ 。SPMLL的任务是从 $\tilde{D}$ 中推导出一个多标签分类器 $f: \mathcal X \to 2^{\mathcal Y}$，该分类器可以为未见实例分配一组相关的标签集。

凭经验验证了 SPMLL 将减少监督量，并对分类性能造成可容忍的损害。直观的解AN是假设未被观察到的标签都是负标签，这导致了引入一些假负标签的缺点。因此，SOTA方法旨在通过利用DNN的学习能力来减少假负标签的破坏性影响，在实践中取得了良好的性能。

然而，目前还没有可以提供理论见解的方法。


# 方法

## 风险一致性估计量

为处理单正多标签学习，分类风险 $R(f)$ 可改写为

![](./图片/%E9%A3%8E%E9%99%A9%E4%B8%80%E8%87%B4%E4%BC%B0%E8%AE%A1%E5%99%A8.png)



